### 程序局部性原理

- **时间局部性**
  - 如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问（因为程序中存在大量的循环）。
- **空间局部性**
  - 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的）。

#### 从硬件和操作系统层面看如何利用局部性

- **硬件层**
  - 局部性原理允许硬件引入**高速缓存存储器**这种小而快速的存储器来存储最近被引用的指令和数据，从而提高对主存的访问速度。
- **操作系统**
  - 允许系统使用主存作为虚拟地址空间作为最近被引用块的高速缓存，**快表**就是将近期常访问的页表项副本放到更高速的联想寄存器中。

#### 从存储结构看如何利用局部性

![存储器层次结构](/Users/wushengna/manual/img/img-post/存储器层次结构.png)

存储器层次结构的中心思想是，对于每个 k，位于 k 层的更快更小的存储设备作为位于 k + 1 层的更大更慢的存储设备的缓存。

- **时间局部性**
  - 同一数据对象可能被多次使用。一旦一个数据对象在第一次被命中时被复制到缓存中，我们就会期望后面对目标有一系列的访问命中，因为缓存比低一层的存储设备更快。
- **空间局部性**
  - 块通常包含多个数据对象。我们会期望后面对该块中其他对象的访问能补偿不命中后复制该块的花费。

### 存储器层次结构

#### 层次结构

本地磁盘 -> 主存(DRAM) -> L3高速缓存(SRAM) -> L2高速缓存(SRAM) -> L1高速缓存(SRAM) -> L0寄存器

#### 缓存思想

- 位于K层的更快更小的存储设备作为位于K+1层更大更慢的存储设备的缓存。

- K+1层的存储器被划分成连续的数据对象组块，称为块，数据总是以块大小为传送单元在K和K+1层之间来回复制。

#### 缓存命中

- 当程序需要K+1层的某个数据对象d时，首先在当前存储在K层的块中查找d，若d刚好缓存在k层中，则称为缓存命中。

- 若缓存不命中，则需要将K+1层中包含对象d的块缓存到K层中，若K层中满了，则需要替换现存的一个块。

### 冯诺依曼结构有哪几个模块，分别对应现代计算机的哪几个部分

* 存储器：内存。
* 控制器：南桥北桥。
* 运算器：CPU。
* 输入设备：键盘。
* 输出设备：显示器、网卡。

### 库函数和系统调用的区别

- **库函数调用**是**语言或应用程序**的一部分，而**系统调用**是**操作系统**的一部分，跨平台技术的原理就是通过库函数实现的，**库函数可以理解为是对系统调用的一层封装，但库函数不是必须包含系统调用**。
- 库函数有可能包含有一个系统调用，有可能有好几个系统调用，当然也有可能没有系统调用，比如有些操作不需要涉及内核的功能。

#### 区别

- 所有 C 函数库是相同的，而各个操作系统的系统调用是不同的。

- 函数库调用是调用函数库中的一个程序，而系统调用是调用系统内核的服务。

- 函数库调用是与用户程序相联系，而系统调用是操作系统的一个进入点。

- 函数库调用是在用户地址空间执行，而系统调用是在内核地址空间执行。

- 函数库调用的运行时间属于**用户**时间，而系统调用的运行时间属于**系统**时间。

- 函数库调用属于过程调用，开销较小，而系统调用需要切换到内核上下文环境然后切换回来，开销较大。

- 在C函数库libc中大约 300 个程序，在 UNIX 中大约有 90 个系统调用。

- 函数库典型的 C 函数：system，fprintf，malloc，而典型的系统调用：chdir，fork，write，brk。

#### 为什么不直接用函数调用

- 因为读写文件通常是大量的数据（相对于底层驱动的系统调用所实现的数据操作单位），这时，**使用库函数可以大大减少系统调用的次数**。这是因为**缓冲区技术**，在用户空间和内核空间对文件操作都使用了缓冲区，当用户空间缓冲区满或者写操作结束时，才将用户缓冲区的内容写到内核缓存区，同理内核缓冲区满或写结束时，才将内核缓冲区内容写到文件对应的硬件媒介。
- 为了保证可移植性。

#### 库函数的缓冲区

- 对于库函数，如果标准输出连到终端设备（直接输出到屏幕），则它是行缓冲的（遇到回车换行符或者是缓冲区满了才输出）；否则（输出到文件）是全缓冲的（缓冲区填满或者是程序运行结束了才输出）。
- 程序运行结束时，会刷新所有的缓冲区。

由于缓冲机制，也带来了一些问题。解决办法有如下两种：

- 任何时候我们都可以使用fflush(stdout)来刷新标准输出缓冲区。
- 使用不带缓冲的系统调用write替代printf输出。

#### 系统调用底层原理

每个系统调用函数都有一个系统调用号，首先找到系统调用对应的中断号（Linux下是int 0x80），然后在中断向量表中找到对应的中断处理函数，再根据系统调用号，在中断处理函数找到对应系统调用函数进行执行。

### 跨平台技术实现原理

现有跨平台技术就是通过库函数调用实现的，不使用系统函数调用。

- Qt如何识别不同系统。
  - Qt各个操作系统都有特定的宏，然后代码里面根据不同的宏调用不同平台的API。

### 并行和并发

- 并发
  - 在同一时刻只能有一条指令执行，但多个进程指令被快速轮换执行，使得在宏观上具有多个进程同时执行的效果。
- 并行
  - 在同一时刻，有多条指令在多个处理器上同时执行。

### 计算密集任务和IO密集任务

- 计算密集型任务
  - 特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。
  - 虽然可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，**计算密集型任务同时进行的数量应当等于CPU的核心数**。
  - CPU密集可以用多进程，使用多核提高效率。
- IO密集型任务
  - 涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。
  - **对于IO密集型任务，任务越多，CPU效率越高**，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。
  - IO密集可以用多线程，进而减少切换开销。

### 单核CPU/多核CPU/多CPU

1. 都是一个CPU，不同的是每个CPU上的核心数。

2. 多核CPU是多个CPU的替代方案，同时也减少了功耗。

3. 一个核心只能同时执行一个线程。

- 单核CPU
  - 一个CPU中只有一个核心处理器。
- 多核CPU
  - 一个CPU有多个核心处理器，处理器之间通过**CPU内部总线**进行通讯。
- 多CPU
  - 简单的多个CPU工作在同一个系统上，多个CPU之间通过**主板上的总线**进行通讯。

#### 深入理解进程和线程

- 进程的调度和资源分配是操作系统负责。
- 线程的调度和资源分配是CPU负责。
- 进程是操作系统资源分配（包括cpu、内存、磁盘IO等）的基本单位，一个CPU同时刻只能执行一个进程。
  - **单核CPU实现多进程，并发。** 通过操作系统的进程调度算法，单核CPU进行进程调度的时候，需要读取上下文+执行程序+保存上下文，即进程切换。
  - **多CPU实现多进程，并行。** 不同的进程运行在不同的CPU上。
- 线程是CPU调度和资源分配的基本单位，一个CPU核心同时刻只能执行一个线程。
  - **单核CPU实现多线程，并发。** 不同线程为了使用CPU核心，则会进行线程切换，但是由于共享了程序执行环境，这个线程切换比进程切换开销少了很多。
  - **多核CPU实现多线程，并行。** CPU可以将不同线程分配到不同的CPU核心处理器中。

1. 单CPU中进程只能是并发，多CPU计算机中进程可以并行。

2. 单CPU单核中线程只能并发，单CPU多核中线程可以并行。

3. 并行有上限，进程与CPU个数，线程与CPU核心个数有关，并不是所有线程和所有进程都能同时运行。

### 什么时候使用多进程和多线程

- 多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置。
- 单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。
- 单核CPU——IO密集型任务，使用多线程还是为了人机交互方便。
- 多核CPU——IO密集型任务，使用多线程也是为了人机交互方便。
- 频繁修改：需要频繁创建和销毁的优先使用**多线程**。
- 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点。
- 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。
- 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

### 服务器高并发的解决方案

- 应用数据与静态资源分离

  将静态资源（图片，视频，js，css等）单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。

- 客户端缓存

  因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请求获取动态数据。

- 集群和分布式

  集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用。

  分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度。

  可以使用服务器集群和分布式架构，使得原本属于一个服务器的计算压力分散到多个服务器上。同时加快请求处理的速度。

- 反向代理

  在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端。

### 进程（2）

进程是**资源分配**的基本单位。

**进程组成：**PCB（进程描述信息、处理器状态、控制管理信息、资源分配信息等），代码段（程序中代码），数据段 （运行过程中产生的各种数据）。

进程控制块（Process Control Block, PCB，即task_struct）描述进程的基本信息和运行状态，所谓的创建进程，执行程序和撤销进程，都是指对 PCB 的操作，PCB 是进程存在的唯一标识，系统通过 PCB 的存在而感知进程的存在。系统通过 PCB 对进程进行管理和调度。

### 线程（2）

线程是**独立调度**的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

### 协程（1）

- 协程是**轻量级线程**，拥有自己的寄存器上下文和栈。协程就是子程序在执行时中断并转去执行别的子程序，在适当的时候又返回来执行，协程调度切换时，将寄存器上下文和栈存放在其他地方，而不是存放在函数堆栈里，在切回来的时候，恢复先前保存的寄存器上下文和栈。
- 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。

#### 协程和线程的区别

- 协程最大的优势就是协程**极高的执行效率**。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
- **不需要多线程的锁机制**，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

#### 应用场景

- I/O 密集型任务。
  - 这一点与多线程有些类似，但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程。
  - 当程序在执行 I/O 操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）。
  - 有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权。

### 上下文切换

- **进程**的切换者是**操作系统**，切换时机是根据操作系统自己的切换策略，**用户无感知**。进程的切换内容包括**页全局目录、内核栈、硬件上下文**，切换内容保存**在内存中**。进程切换过程是由**“用户态到内核态到用户态”**的方式，**切换效率低**。
- **线程**的切换者是**操作系统**，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括**内核栈和硬件上下文**。线程切换内容保存**在内核栈中**。线程切换过程是由**“用户态到内核态到用户态”**， **切换效率中等**。
- **协程**的切换者是**用户**（编程者或应用程序），切换时机是用户自己的程序所决定的。协程的切换内容是**硬件上下文**，切换内存保存**在用户自己的变量（用户栈或堆）中**。协程的切换过程**只有用户态，即没有陷入内核态**，**因此切换效率高**。

### 进程上下文，线程上下文和中断上下文（2）

**进程上下文**

进程上下文就是一个进程在执行的时候，**CPU的所有寄存器中的值，进程的状态，进程ID，指向可执行文件的指针以及堆栈上的内容**，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。

**线程上下文**

当线程被抢占时，就会发生线程之间的上下文切换，如果线程属于相同的进程，它们共享相同的地址空间，因为线程包含在它们所属于的进程的地址空间内，这样进程需要恢复的多数信息对于线程而言是不需要的，线程上下文是指**线程ID，寄存器的值和堆栈的内容**。

**中断上下文**

硬件通过中断触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。中断上文就是**硬件传递过来的这些参数和内核需要保存的一些其他环境，主要是当前被中断的进程环境**。中断下文就是**执行在内核空间的中断服务程序**。

### 进程启动过程

- 内核将程序读入内存，为程序分配内存空间;
- 内核为该进程分配进程标识符（PID）和其他所需资源;
- 内核为进程保存 PID 及相应的状态信息，把进程放到运行队列中等待执行，程序转化为进程后就可以被操作系统的调度程序调度执行了。
- 进程创建时会分配4G的内存，其中0-3G是用户空间，3-4G是内核空间，PCB存在于内核空间。

### PCB

- 每个进程的PCB都是存在所有进程共享的内核空间中，操作系统管理进程，也就是在内核空间中管理的，在内核空间中通过链表管理所有进程的PCB，如果有一个进程要被创建，实际上多分配了这么一个4G的虚拟内存，并在共享的内核空间中的双向链表中加入了自己的PCB。
- PCB(Process Control Block)进程控制块，描述进程的基本信息和运行状态，进程的创建和销毁都是对PCB进行操作，PCB的具体内容如下：
  - 标识相关：pid，ppid等。
  - 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表。
  - 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息。
  - 优先级相关：进程相对于其他进程的调度优先级。
  - 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
  - 状态相关：进程当前的状态，说明该进程处于什么状态。
  - 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号。
  - I/O相关：记录进程与各种I/O设备之间的交互。
- 每个进程的内核空间中都有PCB，但真正的PCB是存储在物理内存上的，当进程创建和销毁时，会由操作系统操作PCB，每个进程只是虚拟地址空间，并不会存储实际数据，数据存储在物理内存中，只有一份。

### 进程间共享和私有资源

- 私有：地址空间、堆、全局变量、栈、寄存器（0-3G的用户空间）。
- 共享：3-4G的内核空间。

### Linux理论上最多可以创建多少个进程，一个进程可以创建多少线程，和什么有关

32768，因为进程的pid是用pid_t来表示的，pid_t的最大值是32768，所以理论上最多有32768个进程，理论上，一个进程可用虚拟空间是2G，默认情况下，线程的栈的大小是1MB，所以理论上最多只能创建2048个线程。如果要创建多于2048的话，必须修改编译器的设置。因此，一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定，只要虚拟空间足够，那么新线程的建立就会成功。如果需要创建超过2K以上的线程，减小你线程栈的大小就可以实现了，虽然在一般情况下，你不需要那么多的线程。过多的线程将会导致大量的时间浪费在线程切换上，给程序运行效率带来负面影响。

### 通常在Linux/windows平台下栈空间的大小

在Linux下栈空间通常是8M，Windows下是1M。

### 进程间同步

#### 临界区

对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```c++
// entry section
// critical section;
// exit section
```

#### 同步与互斥

**同步：**多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。

**互斥：**多个进程在同一时刻只有一个进程能进入临界区。

#### 信号量

信号量（Semaphore）是一个整型变量，可以对其执行P和V操作。

- P：如果信号量大于0，执行减1操作;如果信号量等于0，进程睡眠，等待信号量大于0，申请资源。
- V：对信号量执行加1操作，唤醒睡眠的进程让其完成P操作，释放资源。

P和V操作需要被设计成原语，不可分割，通常的做法是**在执行这些操作的时候屏蔽中断**。如果信号量的取值只能为0或者1，那么就成为了互斥量（Mutex），0表示临界区已经加锁，1表示临界区解锁。

#### 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程**把控制的代码独立出来**，不仅不容易出错，也使得客户端代码调用更容易。

管程有一个重要特性：**在一个时刻只能有一个进程使用管程。**进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了**条件变量**以及相关的操作：**wait()**和**signal()**来实现同步操作。对条件变量执行wait()操作会导致调用进程阻塞，把管程让出来给另一个进程持有，signal()操作用于唤醒被阻塞的进程。

### fork，vfork和clone（1）

fork、v_fork、clone底层都是do_fork，追踪发现底层使用的是sys_clone。

- fork
  - 父进程fork之后创建子进程，子进程复制父进程的所有资源，子进程的代码段、数据段、堆栈都是指向父进程的物理空间，但此时仅仅是子进程的虚拟地址空间和父进程指向的物理地址空间建立了映射关系，并没有真正复制。
  - 由于fork()后会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制技术-Copy-On-Write”。
  - 若两个进程一直只是读数据，则子进程一直不会复制，直到任一进程进行写操作。
  - 父进程和子进程执行顺序没有规定，可以乱序执行。
  - 读时共享，写时复制。
- vfork
  - vfork也是创建一个子进程，但是子进程共享父进程的空间。在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()。
  - 规定必须子进程先执行。
  - 严格意义上讲，vfork产生的不叫进程，因为他没有独立的地址空间，和父进程共享同一个。

### 进程间通信（4）

IPC，通过内核提供的缓冲区进行数据交换的机制。

**1.管道**

无名管道（内存文件）：管道是一种**半双工**的通信方式，数据只能单向交替流动，而且**只能在具有亲缘关系的进程之间使用**，进程的亲缘关系通常是指父子进程或者兄弟进程关系，父进程先创建管道，再创建子进程，这样子进程可以对管道的fd共享，管道的实质是一个**内核缓冲区**（特殊文件，只存在于内存中），进程以先进先出的方式从缓冲区存取数据。管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写，通信双方的进程中写数据的一方需要把fd[0]先close，读的一方需要把fd[1]先close，管道是最容易实现的。

```c
#include <unistd.h>
int pipe(int fd[2]); //返回值：失败返回-1，成功返回0
```

![管道](/Users/wushengna/manual/img/img-post/管道.png)

**管道读写两端可能产生的情况**

- 读管道：
  - 写端全部关闭--read读到0，相当于读到文件末尾。
  - 写端没有全部关闭。
    - 有数据--read读到数据。
    - 没有数据--read阻塞，fcntl函数可以更改为非阻塞。
- 写管道：
  - 读端全部关闭--产生一个信号SIGPIPE，程序异常终止。
  - 读端没有全部关闭。
    - 管道已满--write阻塞。
    - 管道未满--write正常写入。

**2.FIFO**

有名管道（FIFO文件，借助文件系统）：有名管道也是半双工的通信方式，但是**允许在没有亲缘关系的进程之间使用**。

```c
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

**3.消息队列**

消息队列是**一个消息的链表，存放在内核中并由消息队列标识符标识**。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。相比于 FIFO，消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难。避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法。读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

**4.信号**

**用于通知接收进程某个事件已经发生**，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，直到该进程恢复执行并传递给他为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。信号是开销最小的。

- 9)SIGKILL和19)SIGSTOP信号，不允许忽略和捕捉，只能执行默认动作，甚至不能将其设置为阻塞。它们向超级用户提供一种使进程终止或停止的可靠方法。如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是未定义的。

  - 僵尸进程无法杀死，因为僵尸进程已经死了，它在等待父进程对其进行捕获。
  - 处于阻塞状态的进程只有再次唤醒后才会被 kill 掉。
  - init 进程是 Linux 的初始化进程，这个进程会忽略任何信号。
  - SIGKILL 通常是作为最后杀死进程的信号，它通常作用于 SIGTERM 没有响应时发送给进程。

- 系统api产生信号。

  - kill函数，发送信号：`int kill(pid_t pid, int sig);`

    用kill函数发送信号，在接收进程里，通过signal或者sigaction函数调用sighandler，来启动对应的函数处理信号消息。

    - pid > 0，要发送进程ID。
    - pid = 0，代表当前调用进程组内所有进程。
    - pid = -1，代表有权限发送的所有进程。
    - pid < 0，代表-pid对应的组内所有进程。
    - sig，代表对应的信号。

  - raise函数，给自己发送信号：`int raise(int sig);`

  - abort函数，给自己发送异常信号：`void abort(void);`

- 时钟信号

  - alarm函数：`unsigned int alarm(unsigned int seconds);`

    - 定时给自己发送SIGALRM。
    - seconds，代表多少秒后发送信号。
    - 返回值，上次闹钟剩余的秒数。
    - 如果传入参数秒数为0，代表取消闹钟。

  - setitimer函数，周期性的发送信号：

    ```c++
    struct itimerval{
      struct timeval it_interval; //周期性的时间设置
      struct timeval it_value; //下次的闹钟时间
    };
    
    struct timeval{
      time_t tv_sec; //秒
      suseconds_t tv_usec; //微秒
    };
    
    int setitimer(int which, const struct itimerval *new_value, struct itimerval *old_value);
    ```

    - which
      - ITIMER_REAL，自然定时法SIGALRM。
      - ITIMER_VIRTUAL，计算进程执行时间SIGVTALRM。
      - ITIMER_PROF，进程执行时间加调度时间ITIMER_VIRTUAL。
    - new_value，代表要设置的闹钟时间。
    - old_value，代表原闹钟时间。
    - 返回值，成功返回0，失败返回-1。

- 信号集处理函数

  - 清空（清0）信号集：`int sigemptyset(signet_t *set);`
  - 填充（填1）信号集：`int sigfillset(signet_t *set);`
  - 添加某个信号到信号集：`int sigaddset(signet_t *set, int signum);`
  - 从集合中删除某个信号：`int sigdelset(signet_t *set, int signum);`
  - 是否为集合里的成员：`int sigismember(const signet_t *set, int signum);`
    - 返回1代表signum在集合中，返回0代表不在集合中。
  - 设置阻塞或者解除阻塞信号集：`int sigprocmask(int how, const signet_t *set, signet_t *oldset);`
    - how
      - SIG_BLOCK，代表设置阻塞。
      - SIG_UNBLOCK，代表解除阻塞。
      - SIG_SETMASK，代表设置set为新的阻塞信号集。
    - set，代表传入的信号集。
    - oldset，代表旧的信号集，用于传出。
    - 返回值，成功返回0，失败返回-1。
  - 获取未决信号集：`int sigpending(signet_t *set);`
    - set，代表传出参数，当前的未决信号集。

- 信号捕捉

  - 防止进程意外死亡：

    ```c++
    typedef void(*sighandler_t)(int);
    sighandler_t signal(int signum, sighandler_t handler);
    ```

    - signum，代表要捕捉的信号。
    - handler，代表要执行的捕捉函数指针，自定义回调函数，函数应该声明`void func(int);`。

  - 注册捕捉函数：

    ```c++
    struct sigaction{
      void (*sa_handler)(int); //函数指针
      void (*sa_sigaction)(int, siginfo_t *, void *);
      sigset_t sa_mask; //执行捕捉函数期间，临时屏蔽的信号集
      int sa_flags; //一般填0，SA_SIGINFO会使用第二个函数指针
      void (*sa_restorer)(void); //无效
    }
    
    int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);
    ```

    - signum，代表要捕捉的信号。
    - act，代表传入的动作。
    - oldact，代表原动作，用于恢复现场。
    - 返回值，成功返回0，失败返回-1。

- SIGCHILD信号处理，子进程在暂停或者退出的时候会发送SIGCHILD信号，我们可以通过捕捉SIGCHILD信号来回收子进程。

**信号处理机制**

每个进程之中，都有存着一个表，里面存着每种信号所代表的含义，内核通过设置表项中每一个位来处理信号。

- 信号的接收
  - 接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。
- 信号的检测
  - 进程陷入内核态后，有两种场景会对信号进行检测：
    - 进程从内核态返回到用户态前进行信号检测。
    - 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测。
  - 当发现有新信号时，便会进入下一步，信号的处理。
- 信号的处理
  - ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
  - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。

**信号通知进程，为什么通过内核转发**

- 之所以要通过内核来转发，这样做的目的应该也是为了对进程的管理和安全因素考虑。
- 因为在这些信号当中，SIGSTOP和SIGKILL这两个信号是可以将接收此信号的进程停掉的，而这类信号，肯定是需要有权限才可以发出的，不能够随便哪个程序都可以随便停掉别的进程。

**信号处理示例**

- A，B两个进程，A进程发送信号给B进程，信号并不是直接从进程A发送给进程B，而是要通过内核来进行转发。
- A进程发送的信号消息，由内核对B进程相应的表项进行设置。
  - 内核接受到这个信号消息后，会先检查A进程是否有权限对B进程的信号表对应的项进行设置。
    - 如果可以，就会对B进程的信号表进行设置。
    - 如果不可以，就忽略。
    - 信号处理有个特点，就是没有排队的机制，也就是说某个信号被设置之后，如果B进程还没有来及进行响应，那么如果后续第二个同样的信号消息过来，就会被阻塞掉，也就是丢弃。
  - 内核对B进程信号设置完成后，就会发送中断请求给B进程，这样B进程就进入到内核态。
  - 进程B根据那个信号表，查找对应的此信号的处理函数，保护现场，跳回到用户态执行信号处理函数，处理完成后，再次返回到内核态，再次保护现场，然后再次返回用户态，从中断位置开始继续执行。
  - 保护现场是在用户态和内核态之间跳转的时候，对堆栈现场的压栈保存。

**5.信号量**

信号量是**一个计数器，可以用来控制多个进程对共享资源的访问**。信号量只有等待和发送两种操作，等待(P(sv))就是将其值减一或者挂起进程，发送(V(sv))就是将其值加一或者将进程恢复运行。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问，分为两种POSIX信号量和SystemV信号量。

**POSIX信号量**

- 有名信号量，用于进程间同步。
- 无名信号量，用于线程间同步。
  - posix信号量一般是单个计量信号，全程操作一个信号量。

**SystemV信号量**

- 用于进程间同步，进程中使用共享内存实现进程间通信，但他并不是线程安全的，需要通过信号量进行同步。
- 一般说的systemV信号量是计量信号集，可以使用多个信号量进行同步。

- 创建信号量：`int semget(key_t key, int nsems, int semflag);`

  创建成功返回信号量标识符，失败返回-1。

  - key：进程pid。
  - nsems：创建信号量的个数。
  - semflag：指定信号量读写权限。

- 改变信号量值：`int semop(int semid, struct sembuf *sops, unsigned nsops);`

  我们所需要做的主要工作就是串讲sembuf变量并设置其值，然后调用semop，把设置好的sembuf变量传递进去。

  struct sembuf结构体定义如下：

  ```c++
  struct sembuf{
      short sem_num;
      short sem_op;
      short sem_flg;
  };
  ```

  成功返回信号量标识符，失败返回-1。

  - semid：信号量集标识符，由semget()函数返回。
  - sops：指向struct sembuf结构的指针，先设置好sembuf值再通过指针传递。
  - nsops：进行操作信号量的个数，即sops结构变量的个数，需大于或等于1。最常见设置此值等于1，只完成对一个信号量的操作。

- 直接控制信号量信息：`int semctl(int semid, int semnum, int cmd, union semun arg);`

  - semid：信号量集标识符。
  - semnum：信号量集数组上的下标，表示某一个信号量。
  - arg：union semun类型。

**6.共享内存**

共享内存就是**映射一段能被其他进程所访问的内存**，这段共享内存由一个进程创建，但多个进程都可以访问。因为**数据不需要在进程之间复制**，共享内存是最快的IPC方式，缺点是没有提供同步机制，需要使用锁等其他机制进行同步，**它往往与信号量配合使用来实现进程间的同步和通信**。多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存，另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。共享内存有两种shm和mmap，IPC通信System V版本的共享内存shm，存储映射I/O（mmap函数）。

**shm原理**

shm多个进程的地址空间映射到同一个物理内存，不同进程可以将同一段共享的内存连接到自己的地址空间中，从而所有进程都可以访问共享内存中的地址。

- 创建共享内存：`int shmget(key_t key, int size, int flag);`

  成功时返回一个和key相关的共享内存标识符，失败返回-1。

  - key：为共享内存段命名，多个共享同一片内存的进程使用同一个key。
  - size：共享内存容量。
  - flag：权限标志位，和open的mode参数一样，若key标识的共享内存不存在，通过0666|IPC_CREAT来创建，并设置权限。

- 连接到共享内存地址空间：`void *shmat(int shmid, void *addr, int flag);`

  返回值即共享内存实际地址。

  - shmid：shmget()返回的标识。
  - addr：决定以什么方式连接地址。
  - flag：访问模式。

- 从共享内存分离，将共享内存分离并不是删除它，只是使该共享内存对当前进程不再可用：`int shmdt(const void *shmaddr);`

  调用成功返回0，失败返回-1。

  - shmaddr：是shmat()返回的地址指针。

- 释放物理内存中的那块共享内存：`int shmctl(int shmid, int cmd, struct shmid_ds* buf);`

  - cmd取IPC_RMID表示删除这块共享内存。

**创建映射区**

```c++
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
```

- addr是地址，传NULL。
- length是映射区长度。
- prot
  - PROT_READ表示可读。
  - PROT_WRITE表示可写。
- flags
  - MAP_SHARED表示共享的，对内存的修改会影响到源文件。
  - MAP_PRIVATE表示私有的，对内存的修改不会影响到源文件。
  - MAP_ANON实现匿名映射，可以不打开文件进行映射，只能在有血缘关系进程之间通信。
- fd是文件描述符，使用open打开一个文件，然后通过文件建立一个映射区。
- offset是偏移量，一定要是4k的整数倍。
- 返回值
  - 成功返回可用的内存首地址。
  - 失败返回MAP_FAILED。

**释放映射区**

```c++
int munmap(void *addr, size_t length);
```

- addr是地址，传mmap的返回值。
- length是长度，mmap创建的长度。
- 返回值
  - 成功返回0。
  - 失败返回1。

**mmap原理**

- mmap是映射磁盘上的一个文件，每个进程在自己的逻辑地址空间中开辟一块空间对磁盘上的文件进行映射。
- 内存映射的过程中，并没有实际的数据拷贝，文件没有被载入内存。
- mmap返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，通过ptr就能够操作文件。但是ptr所指向的是一个逻辑地址，要操作其中的数据，必须通过MMU将逻辑地址转换成物理地址，建立内存映射并没有实际拷贝数据，这时，将产生一个缺页中断，会通过mmap()建立的映射关系，从硬盘上将文件读取到物理内存中。

**mmap效率**

- read()是系统调用，其中进行了数据拷贝，它首先将文件内容从硬盘拷贝到内核空间的一个缓冲区，然后再将这些数据拷贝到用户空间，在这个过程中，实际上完成了两次数据拷贝。
- mmap()也是系统调用，mmap()中没有进行数据拷贝，真正的数据拷贝是在缺页中断处理时进行的，由于mmap()将文件直接映射到用户空间，所以中断处理函数根据这个映射关系，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝。

**mmap映射文件**

- 普通文件
  - open系统调用打开一个文件，然后进行mmap操作，得到共享内存，这种方式适用于任何进程之间。
- 匿名映射
  - 调用 mmap 时，在参数 flags 中指定 MAP_ANONYMOUS 标志位，并且将参数 fd 指定为 -1 ,用于父子进程之间。

**不同进程访问共享内存**

- shm
  - 不同进程通过shmget->shmat函数，将共享内存连接到自己的虚拟内存地址。
- mmap
  - 不同进程通过mmap函数创建映射区，将自己的内存虚拟地址映射到磁盘的文件上。

**程序异常退出，共享内存会释放吗**

- 不会
  - Linux中通过API函数shmget创建的共享内存一般都是在程序中使用shmctl来释放的，但是有时为了调试程序，开发人员可能通过Ctrl + C等方式发送中断信号来结束程序，此时程序申请的共享内存就不能得到释放，当然如果程序没有改动的话，重新运行程序时仍然会使用上次申请的共享内存，但是如果我们修改了程序，由于共享内存的大小不一致等原因会导致程序申请共享内存错误。
- 如何释放
  - 如果总是通过Crtl+C来结束的话，可以做一个信号处理器，当接收到这个信号的时候，先释放共享内存，然后退出程序。 
  - 不管你以什么方式结束程序，如果共享内存还是得不到释放，那么可以通过linux命令ipcrm shm shmid来释放，在使用该命令之前可以通过ipcs -m命令来查看共享内存。

**mmap和shm的区别**

- 作用
  - mmap系统调用并不完全是为了共享内存来设计的，它本身提供了不同于一般对普通文件的访问的方式，进程可以像读写内存一样对普通文件进行操作。
  - IPC的共享内存shm是纯粹为了共享。
- 映射位置
  - mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间对磁盘上的文件进行映射。
  - shm每个进程映射到同一块物理内存，shm保存在物理内存，这样读写的速度要比磁盘要快，但是存储量不是特别大。
- 内容丢失
  - 进程挂了重启不丢失内容，二者都可以做到。
  - 机器挂了重启，mmap把文件存在磁盘上，可以不丢失内容（文件内保存了OS同步过的映像），而 shmget 会丢失。

**7.套接字**

**适用于不同机器间进程通信**，在本地也可作为两个进程通信的方式。

### 进程调度算法（2）

#### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

- 先来先服务 first-come first-serverd（FCFS）
  - **非抢占式**的调度算法，**按照请求的顺序进行调度**。
  - **有利于长作业（CPU繁忙性），但不利于短作业（I/O繁忙性）**，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

- 短作业优先 shortest job first（SJF）
  - **非抢占式**的调度算法，**按估计运行时间最短的顺序进行调度**。
  - **长作业有可能会饿死**，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。完全未考虑作业的优先紧迫程度，**不能用于实时系统**。

- 最短剩余时间优先 shortest remaining time next（SRTN）
  - 最短作业优先的**抢占式**版本，**按剩余运行时间的顺序进行调度**。
  - 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程，否则新的进程等待。该算法确保一旦新的短作业或短进程进入系统，能够很快得到处理。

#### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

- 时间片轮转
  - 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
  - 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

- 优先级调度
  - 为每个进程分配一个优先级，按优先级进行调度。
  - 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

- 多级反馈队列
  - 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
  - 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
  - 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
  - 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

#### 实时系统

- 实时系统要求一个请求在一个确定时间内得到响应。
- 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

### 进程调度时机

- 进程状态转换的时刻：进程终止、进程睡眠；
- 当前进程的时间片用完时（current->counter=0）；
- 设备驱动程序；
- 进程从中断、异常及系统调用返回到用户态时；

### 进程的执行过程是什么样的

进程的执行需要经过三大步骤：编译，链接和装入。

* 编译：将源代码编译成若干模块。
* 链接：将编译后的模块和所需要的库函数进行链接。链接包括三种形式：静态链接，装入时动态链接（将编译后的模块在链接时一边链接一边装入），运行时动态链接（在执行时才把需要的模块进行链接）。
* 装入：将模块装入内存运行。

将进程装入内存时，通常使用分页技术，将内存分成固定大小的页，进程分为固定大小的块，加载时将进程的块装入页中，并使用页表记录。减少外部碎片。通常操作系统还会使用虚拟内存的技术将磁盘作为内存的扩充。

### 线程间共享和私有资源（1）

- 私有：**线程栈，寄存器，程序寄存器**，线程ID，错误返回码，信号屏蔽字，调度优先级。
- 共享：文件描述符表，堆，地址空间，全局变量，静态变量，进程代码段，进程的当前目录和进程用户ID与进程组ID。

### 线程间同步和系统调用（4）

**线程同步**就是协调线程的步骤，使线程能顺序执行。

#### 线程间同步方式

- 信号量：若信号量为0则挂起该线程，否则原子地减一，使用完资源后将信号量原子地加一，若有挂起的线程则将其唤醒。
- 互斥量：又叫互斥锁，进入临界区需要加锁，离开临界区需要解锁。
- 条件变量：用于线程间同步共享数据，当某个数据达到指定条件时，唤醒等待这个数据的一个或者多个线程。

#### 互斥量

##### 互斥锁

**互斥锁的使用步骤**

- 初始化
- 加锁
- 执行逻辑（操作共享数据）
- 解锁

**相关接口**

- 初始化互斥锁：`int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);`

  - restrict，用于约束该块内存区域对应的数据，只能通过后面的变量进行访问和修改。
  - mutex，互斥量。
  - attr，代表互斥量的属性。

- 给共享资源加锁：`int pthread_mutex_lock(pthread_mutex_t *mutex);`

  - mutex，代表pthread_mutex_init初始化的锁。

  - 如果当前线程未加锁，成功，给线程加锁。

    如果当前线程已经加锁，则阻塞等待。

- 摧毁锁：`int pthread_mutex_destroy(pthread_mutex_t *mutex);`

  - mutex，代表传入的锁。

- 尝试加锁：`int pthread_mutex_trylock(pthread_mutex_t *mutex);`

  - mutex，代表传入的锁。

  - 如果当前线程未加锁，成功，给线程加锁。

    如果当前线程已经加锁，则直接返回errno。

**死锁**

- 加了一次锁，又加了一次锁。
- 交叉锁。
  - 解决办法：每个线程申请锁的顺序要一致或者如果申请到一把锁，申请另外一把的时候申请失败，应该释放已经掌握的锁。

##### 读写锁

读写锁适合读的线程多的情况，读写锁的特点：读共享，写独占，写优先级高。

读写锁仍然是一把锁，有不同的状态未加锁，读锁和写锁。

**相关接口**

- 初始化：`int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);`
- 销毁读写锁：`int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);`
- 加读锁：`int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);`
- 加写锁：`int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);`
- 释放锁：`int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);`

#### 信号量

信号量是加强版的互斥锁，允许多个线程访问共享资源。

**相关接口**

- 初始化：`int sem_init(sem_t *sem, int pshared, unsigned int value);`
  - sem，代表信号量。
  - pshared
    - 0代表线程信号量。
    - 非0代表进程信号量。
  - value，代表信号量的个数。
- 摧毁信号量：`int sem_destroy(sem_t *sem);`
- 申请信号量：`int sem_wait(sem_t *sem);`
  - 申请成功，value--
  - 当信号量为0时，阻塞。
- 释放信号量：`int sem_post(sem_t *sem);`
  - value++

#### 条件变量

条件变量不是锁，要和互斥量一起使用，条件变量避免了无效竞争。

**相关接口**

- 条件变量阻塞等待：`int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);`
  - 先释放锁mutex。
  - 阻塞在cond条件变量上。
- 销毁一个条件变量：`int pthread_cond_destroy(pthread_cond_t *cond);`
- 初始化一个条件变量：`int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr);`
- 唤醒至少一个阻塞在条件变量cond上的线程：`int pthread_cond_signal(pthread_cond_t *cond);`
- 唤醒阻塞在条件变量cond上的全部线程：`int pthread_cond_broadcast(pthread_cond_t *cond);`

### 程序和进程的区别

程序是编译好的二进制文件，进程通俗讲就是运行的程序，资源分配主要是对CPU和内存进行分配，主要区别是：

- 程序占用磁盘，不占用系统资源，内存占用系统资源，即进程占用系统资源。
- 一个程序对应多个进程，一个进程对应一个程序。
- 程序没有生命周期，进程有生命周期。

### 进程和线程的区别与联系（6）

#### 区别

**I 拥有资源**

进程占有资源，但是线程不占有，线程可以访问隶属进程的资源。

进程所维护的是程序所包含的资源(**静态资源**)， 如：**地址空间，打开的文件句柄集，文件系统状态， 信号处理handler**等;

线程所维护的运行相关的资源(**动态资源**)，如：**运行栈，调度相关的控制信息，待处理的信号集**等; 

**II 调度**

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。进程切换开销大，由切换页全局目录和切换内核态堆栈和硬件上下文（一组寄存器值）两步组成，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，线程切换只是把寄存器值保存到内核堆栈里，再加载被调度线程的寄存器值。

**III 系统开销**

线程创建销毁只需要处理PC值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁系统都要为之分配或回收资源，如内存空间、I/O 设备等，需要重新分配及销毁task_struct结构，所付出的开销远大于创建或撤销线程时的开销。

**IV 通信方面**

线程间可以通过直接读写同一进程中的数据段（如全局变量，信号和事件）进行通信，但是进程通信需要借助 IPC，如管道，信号，消息队列，共享内存，套接字等通信机制，需要进程同步和互斥手段的辅助，以保证数据的一致性。

**V 健壮性**

线程、进程之间都可以并发，多进程程序比多线程程序更健壮，进程之间不会相互影响，因为进程有自己独立的地址空间；而一个线程崩溃会导致进程崩溃，从而影响同一个进程里面的其他线程。

#### 联系

线程是存在进程的内部，一个进程中可以有多个线程，一个线程只能存在一个进程中。

### TLB

TLB（Translation Look- aside buffer）**快表**专门用于缓存内存中的页表项，**一般在MMU单元内部**，**页表一般存储在物理内存中**。当处理器要访问一个虚拟地址时，首先会在TLB中查询，如果TLB表项中没有相应的表项，称为TLB Miss，那么就需要访问页表来计算出相应的物理地址，如果TLB表项中有相应的表项，那么直接从TLB表项中获取物理地址，称为TLB命中。

### 程序计数器PC和指令指针寄存器IP

- 程序计数器PC
  - 用指令事先编好的程序连续存放在内存程序区中，靠地址+1的方法连续取指令执行。在八位机8080CPU中是采用先取址后执行的串行操作的原理，而其中执行地址+1指令寻址的部件就是程序计数器PC。那么在程序的执行过程中，PC始终是指向下一条要执行的指令。
  - 结论：PC中的地址就是需要转移、循环、调用子程序和中断子程序等操作时的断点。
- 指令指针寄存器IP
  - 在向上兼容的十六位机8086CPU中首先分为两个功能部件，即总线接口部件BIU和执行部件EU，BIU负责取指令，EU负责译码执行。并且当BIU执行指令排队栈中的六个字节装满后，（8088CPU是4个字节），EU开始从指令排队栈的出栈口，取指令进行译码执行，同时BIU并行操作向入栈口补充一条取指令命令。
  - 指令指针IP则是指向下一条要取址的指令，而不是EU要执行的指令。而断点则应该是要执行的指令内存地址，而不是IP内的下一条要取指的指令地址。
- PC是模型机中的概念，IP是实际使用的，调试时我们发现，IP实现的就是PC的功能。

### 为什么有了进程还需要线程

- 优点
  - 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量。
- 缺点
  - 进程在同一时间只能干一件事。
  - 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。

### 进程状态切换

![进程状态切换](/Users/wushengna/manual/img/img-post/进程状态切换.png)

- 就绪状态（ready）：等待被调度。
- 运行状态（running）
- 阻塞状态（waiting）：等待资源。

应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

进程控制会导致进程状态的转换，无论哪个进程控制原语， 要做的无非三类事情：

1. 更新PCB中的信息。
   a. 所有的进程控制原语一定都会修改进程状态标志。
   b. 剥夺当前运行进程的CPU使用权必然需要保存其运行环境。
   c. 某进程开始运行前必然要恢复其运行环境。
2. 将PCB插入合适的队列。
3. 分配/回收资源。

### 孤儿进程与僵尸进程

**孤儿进程**是指父进程退出后它的子进程还在执行，孤儿进程会被init进程收养并完成状态收集（危害不大）。

回收方法：`kill -9 pid`

**僵尸进程**是指子进程完成并退出后父进程没有使用`wait()`或者`waitpid()`对它们进行状态收集，这些子进程的进程描述符（PCB）仍然会留在系统中，占用进程号等资源（危害极大）。

回收方法：杀死父进程，init领养。

**相关接口**

- **回收子进程1：**`pid_t wait(int *status);`

  一旦调用`wait()`，就会立即阻塞自己，`wait()`自动分析某个子进程是否已经退出，如果找到僵尸进程就会负责收集和销毁，如果没有找到就一直阻塞在这里，status传出参数指向子进程结束状态值。

  返回值：成功返回终止子进程ID，失败返回-1。

  作用：

  - 阻塞等待。
  - 回收子进程资源。
  - 查看死亡原因。

  子进程死亡原因：

  - 正常死亡`WIFEXITED`
    - 如果`WIFEXITED`为真，使用`WEXITSTATUS`得到退出状态。
  - 非正常死亡`WIFSIGNALED`
    - 如果`WIFSIGNALED`为真，所用`WTERMSIG`得到信号。

- **回收子进程2：**`pid_t waitpid(pid_t pid, int *status, int options);`

  - `waitpid()`相当于`wait()`的封装，多了两个由用户控制的参数`pid`和`options`，可以自定义回收的子进程进程号，并设置是否阻塞。
  - `pid`
    - `pid < -1` 回收进程组识别码为`pid`绝对值的任何进程。
    - `pid = -1` 回收任意子进程。
    - `pid = 0` 回收和调用进程组id和当前进程相同组内的子进程。
    - `pid > 0` 回收指定进程识别码为`pid`的子进程。
  - `options`
    - `0`与`wait()`相同，也会阻塞。
    - `WNOHANG`如果当前没有子进程退出会立刻返回。
  - `WUNYRACED`子进程进入暂停马上返回，但结束状态不予理会。
  
  返回值：如果设置了`WNOHANG`，那么如果没有子进程退出，返回`0`，如果有子进程退出，返回退出的`pid`，反之失败返回`-1`（没有子进程）。

### 守护进程

**终端**是linux中每一个系统与用户进行交流的界面，每一个从此终端开始运行的进程都依附于此终端，这个终端称为这些进程的控制终端，当控制终端被关闭时，相应的进程会自动关闭。守护进程可以突破这种限制，从运行开始执行，整个系统关闭才退出。

**会话**是进程组的更高一级，多个进程组对应一个会话。**创建会话**组长不可以创建，必须是组员创建。一个会话期开始于用户登录，终止于用户退出，在此期间该用户运行的所有进程都属于这个会话期。

**进程组**是多个进程在同一个组，第一个进程默认是进程组的组长，进程组由进程组ID来唯一标识，其组长进程的进程号等于进程组ID，且该进程组ID不会因组长进程的退出而受到影响。

**守护进程**是脱离终端并在后台运行的进程，执行过程中信息不会显示在终端上，并且也不会被终端发出的信号打断。

**setsid函数**用于创建新会话，调用setsid的进程将担任会话期的会长，让进程摆脱原会话的控制，原进程组的控制和原控制终端的控制。

**创建守护进程要调用setsid的原因**

- 一般子进程实现守护进程，子进程fork于父进程，子进程全盘拷贝了父进程的会话期，进程组，控制终端。
- 虽然父进程退出了，但子进程的各个属性都没变，不算真正意义的独立。

**创建会话的步骤：**

- 创建子进程。
- 父进程杀死。
- 子进程当会长。

**创建守护进程的步骤：**

- 创建子进程，父进程退出：`fork() + if(pid > 0){exit(0);}`，使子进程成为孤儿进程被init进程收养。
- 在子进程中创建新会话：`setsid()`
- 改变当前目录结构为根：`chdir("/")`（从父进程继承来的工作目录可能是一个挂载的文件系统，若不修改工作目录，该文件系统不能卸载。）
- 重设文件权限掩码（文件权限掩码是指屏蔽掉文件权限中的对应位，由于从父进程继承来的文件权限掩码会屏蔽掉文件权限中的对应位，这给该子进程使用文件带来麻烦。）：`umask(0)`（表示用户，用户组和其他用户都有可读可写可执行权限。）
- 关闭文件描述符（子进程会从父进程继承一些打开的文件描述符，但这些可能永远不会被守护进程使用，但他们一样消耗系统资源，而且会导致所在文件系统无法结束。）：`for(int i = 0; i < 65535; ++i){close(i);}`

**结束守护进程：**`kill -9 pid`

### 用户态和内核态（1）

- 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。

- 用户态拥有最低的特权级，内核态拥有较高的特权级。

- 运行在用户态的程序不能直接访问操作系统内核数据结构和程序。

- 操作系统的数据都是存放于系统空间的，用户进程的数据是存放于用户空间的。**分开来存放，就让系统的数据和用户的数据互不干扰，保证系统的稳定性。**分开存放，管理上很方便，而更重要的是，将用户的数据和系统的数据隔离开，就可以对两部分的数据的访问进行控制。这样就可以确保用户程序不能随便操作系统的数据，这样防止用户程序误操作或者是恶意破坏系统。

#### 用户态和内核态可以通过指针传递数据吗

- 用户态不能访问内核态的指针
  - 为了实现内存的保护，防止越界访问而造成受保护内存的被非法修改，甚至造成系统的崩溃，这种直接传递数据指针来传递数据的方式是被禁止的。
- 内核态可以访问用户态的指针（有前提）
  - 必须保证用户态虚拟空间的指针（虚拟空间的地址），已经分配物理地址，否则指针传入内核态中将不会引发缺页异常而报错。
- 内核中访问用户进程的地址的时候用copy_from_user，而不是用memcpy直接拷贝（或者说使用用户态指针）
  - copy_from_user主要是这个函数提供了两个功能
    - 对用户进程传过来的地址范围进行合法性检查；
    - 当用户传来的地址没有分配物理地址时，定义了缺页处理后的异常发生地址，保证程序顺利执行；
    - 对于用户进程访问虚拟地址，如果还未分配物理地址，就会触发内核缺页异常，接着内核会负责分配物理地址，并修改映射页表。这个过程对于用户进程是完全透明的。但是在内核空间发生缺页时，必须显式处理，否则会导致内核出现错误。
  - 直接使用memcpy时为什么没有出现异常
    - 只有用户传来的地址空间没有分配对应的物理地址时才会进行修复，如果用户进程之前已经使用过这段空间，代表已经分配了物理地址，自然不会发生缺页异常。

#### 两种状态转换

- 系统调用
  - 用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。
- 异常
  - 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此异常的内核相关程序中，也就到了内核态，比如缺页异常。
- 外围设备中断
  - 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序。
  - 比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

### 在执行malloc申请内存的时候，操作系统是怎么做的，内存分配的原理说一下，malloc函数底层是怎么实现的，进程是怎么分配内存的

从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap。

* brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小。
* mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。

通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。

进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过缺页中断，让内核分配相应的物理内存，这样内存分配才算完成。

### 操作系统的内存管理

操作系统的内存管理包括物理内存管理和虚拟内存管理

* 物理内存管理包括交换与覆盖，分页管理，分段管理和段页式管理等。
* 虚拟内存管理包括虚拟内存的概念，页面置换算法，页面分配策略等。

### 什么是虚拟内存（2）

为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存，防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但**不需要映射到连续的物理内存**，也**不需要所有页都必须在物理内存中**。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

#### 虚拟内存的好处

- **可以更加高效的使用物理内存**
  - 虚拟地址空间一开始并没有真正的对应物理地址，而是在真正使用的时候才去对应。
  - 通过虚拟内存置换算法在访问后边的地址空间的时候就可以将前边当前没有在访问的物理页释放掉，或者交换到硬盘中。这样这个物理页又可以去对应新的虚拟地址，从而使物理内存可以充分的利用。
- **内存管理**
  - 为每个进程提供了一致的地址空间，简化内存管理。
- **内存保护**
  - 在使用虚拟地址的时候，暴露给程序员永远都是虚拟地址，而具体的物理地址在哪里，这个只有系统才了解，这样就提高了系统的封装性。
  - 保护了每个进程的地址空间不被其他进程破坏。

### 虚拟内存页表寻址

#### 分页

虚拟内存分割成虚拟页，物理内存被分割成物理页，用来作为磁盘和主存的传输单元，虚拟页分为三个不相交的子集。

- 未分配的，不占磁盘空间。

- 缓存的，当前已缓存在物理内存中的已分配页，在页表中标志位为1。

- 未缓存的，未缓存在物理内存中的已分配页，在页表中标志位为0。

#### 页表

内存管理单元（MMU，属于硬件）管理着地址空间和物理内存的转换，操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，存储着程序地址空间到物理内存空间的映射表。

页表存放在物理内存中，物理页存放在物理内存中，虚拟页存放在磁盘上。

#### 页表寻址

- 一个虚拟地址分为两部分，一部分存储页面号，一部分存储偏移量。

- 页表分为序号、页基地址、标志位。

- 访问虚拟地址，先通过页表查询页面号，查看标志位确认虚拟地址是否在物理内存中有缓存，然后由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移虚拟地址中的偏移量就得到最后的物理地址。

- 一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。

### 缺页中断

在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时（缓存不命中），会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

- 保护CPU现场。

- 分析中断原因。

- 转入缺页中断处理程序进行处理。

- 恢复CPU现场，继续执行。

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

- 在指令执行期间产生和处理缺页中断信号。

- 一条指令在执行期间，可能产生多次缺页中断。

- 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

### 虚拟内存置换算法（1）

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。

当前操作系统最常采用的缺页置换算法如下：

- 先进先出（FIFO）算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

- 最近最少使用（LRU）算法：置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

当前最常采用的就是LRU算法。

### 页式管理，段式管理和段页式管理（1）

#### 页式管理

页式管理是将各进程的虚拟空间划分为若干个长度相等的页，把内存空间按页的大小划分为片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表，并用相应的硬件地址转换机构来解决离散地址变换问题。

**优点：**没有外部碎片，每个内部碎片不超过页的大小。

**缺点：**程序全部装入内存，要求有相应的硬件支持，如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持，增加了机器成本和系统开销。

#### 段式管理

段式管理是把程序按内容或过程函数关系分成段，每段有自己的名字。一个用户作业或者进程所包含的段对应一个二维线性虚拟空间，也就是一个二维虚拟存储器。段式管理程序以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。

**优点：**可以分别编写和编译，可以针对不同类型的段采取不同的保护，可以按段为单位来进行共享，包括通过动态链接进行代码共享。

**缺点：**会产生碎片。

#### 段页式管理

段页式管理，系统必须为每个作业或者进程建立一张段表以管理内存分配与释放、缺段处理等。另外由于一个段又被划分为若干个页，每个段必须建立一张页表以把段中的虚页变换为内存中的实际页面。显然与页式管理时相同，页表也要有相应的实现缺页中断处理和页面保护等功能的表项。

**优点：**段页式管理是段式管理和页式管理相结合而成，具有两者的优点。

**缺点：**由于管理软件的增加，复杂性和开销也增加，另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。

#### 分段与分页的区别

- **页**是信息的物理单位。分页的主要目的是为了**实现离散分配，提高内存利用率**。分页仅仅是系统管理上的需要，完全是**系统行为**，对用户是不可见的。**段**是信息的逻辑单位。分段的主要目的是更好地**满足用户需求**。一个段通常包含着一组属于一个逻辑模块的信息。分段**对用户是可见的**，用户编程时需要显式地给出段名。
- **页的大小**固定且由系统决定。**段的长度**却不固定，决定于用户编写的程序。
- 分页的用户进程地址空间是**一维**的，程序员只需给出一个记忆符即可表示一个地址。分段的用户进程地址空间是**二维**的， 程序员在标识一个地址时， 既要给出段名， 也要给出段内地址。
- 分段比分页更容易实现信息的**共享和保护**。不能被修改的代码称为纯代码或可重入代码（不属于临界资源），这样的代码是可以共享的，可修改的代码是不能共享的。

### 内部碎片和外部碎片

- **内部碎片**:**分配给某些进程的内存区域中有些部分没用上**，常见于**固定分配方式**。
  - 内存总量相同，100M 固定分配，将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片;分段式分配，按需分配，一个程序需要45M，就给分片45MB，剩下的55M供其它程序使用，不存在内部碎片。

- **外部碎片**:**内存中某些空闲区因为比较小，而难以利用上**，一般出现在**内存动态分配方式**中。
  - 分段式分配:内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序使用，只能从头开始分片，这样就会存在10M+5M的外部碎片。

**如何消除碎片文件**

对于外部碎片，通过**紧凑技术**消除，就是操作系统不时地对进程进行移动和整理，但是这需要动态重定位寄存器地支持，且相对费时。紧凑地过程实际上类似于Windows系统中地磁盘整理程序，只不过后者是对外存空间地紧凑。

解决外部内存碎片的问题就是**内存交换**。

可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

回收内存时要尽可能地将相邻的空闲空间合并。

### 异常和中断的区别

**中断**是指CPU对系统发生某事件时的这样一种响应：CPU暂停正在执行的程序，在保留现场后自动地转去执行该事件的中断处理程序；执行完后，再返回到原程序的断点处继续执行。

- **外中断**就是我们指的中断，是指由于外部设备事件所引起的中断，如通常的磁盘中断、打印机中断等；
- **内中断**就是异常，是指由于 CPU 内部事件所引起的中断，如程序出错(非法指令、地址越界)，内中断(trap)也被译为“捕获”或“陷入”。
- **异常**是由于执行了现行指令所引起的，由于系统调用引起的中断属于异常。
- **中断**则是由于系统中某事件引起的，该事件与现行指令无关。

**相同点：**都是**CPU**对**系统**发生的**某个事情**做出的**一种反应**。

**区别：中断**由**外因引起**，**异常**由**CPU本身**原因引起。

### 中断的实现过程（1）

当发生了中断，就意味着需要操作系统的介入，开展管理工作。由于操作系统的管理工作（如进程切换，分配IO设备）需要使用特权指令，因此**CPU要从用户态转换为核心态**，有了中断，才能实现多道程序并发执行，用户态到核心态的转换就是通过中断机制实现的，并且中断是唯一途径。

- 执行完每个指令后，CPU都要检查当前是否有外部中断信号。
- 如果检测到外部中断信号，则需要保护被中断进程的CPU环境（**如程序状态字PSW，程序计数器，各种通用寄存器**）。
- 根据中断信号类型转入相应的中断处理程序。
- 恢复进程的CPU环境并退出中断，返回原进程继续往下执行。

![中断处理过程](/Users/wushengna/manual/img/img-post/中断处理过程.png)

### Linux系统中的锁（2）

互斥锁，读写锁，自旋锁，RCU

- 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。**当获取锁操作失败时，线程会进入睡眠**，等待锁释放时被唤醒。
- 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作，但是同一时刻只能有一个线程可以获得写锁，其它**获取写锁失败的线程都会进入睡眠状态**，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者），适用于读取数据的频率远远大于写数据的频率的场合。
- 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象，但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率，但如果加锁时间过长，则会非常浪费CPU资源。
- RCU：read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改，修改完成后，再将老数据update成新的数据。使用RCU时，**读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了，而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作，写者必须要等它之前的读者全部都退出之后才能释放之前的资源**。在有大量读操作，少量写操作的情况下效率非常高。RCU主要针对的数据对象是链表，在读取过程中，另外一个线程删除了一个节点，删除线程可以把这个节点从链表中移除，但它不能直接销毁这个节点，必须等到所有的读取线程读取完成以后，才进行销毁操作，RCU中把这个过程称为宽限期（Grace period）。在读取过程中，另外一个线程插入了一个新节点，而读线程读到了这个节点，那么需要保证读到的这个节点是完整的，这里涉及到了发布-订阅机制（Publish-Subscribe Mechanism）。保证读取链表的完整性，新增或者删除一个节点，不至于导致遍历一个链表从中间断开，但是RCU并不保证一定能读到新增的节点或者不读到要被删除的节点。

### 死锁产生的条件（1）

多个并发进程因争夺系统资源而产生相互等待的现象。

- 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；
- 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源。
- 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放。
- 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 ，环路中每个进程都在等待下一个进程所占有的资源。

### 如何避免死锁

- **破坏请求和等待条件。** 所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
- **破坏不可抢占条件。** 当进程新的资源未得到满足时，释放已占有的资源。
- **破坏环路等待条件。** 系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反。

### 死锁检测和死锁恢复

- 死锁检测
  - 每种类型一个资源的死锁检测。
  - 每种类型多个资源的死锁检测。
- 死锁恢复
  - **抢占恢复。** 从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。
  - **回滚恢复。** 周期性地检查进程的状态（包括请求的资源），将其写入一个文件，当发生死锁，回滚到之前的某个时间点。
  - **杀死进程恢复。** 终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

### 如何查找死锁的位置（1）

使用gdb调试线程，找到死锁位置。自旋锁占用cpu可能导致线程的cpu利用率到100%，睡眠锁（互斥锁等）不会占用cpu可能不会导致线程的cpu利用率过高。可以使用gdb调试线程函数堆栈，或者gdb调试core文件查看线程函数堆栈，或者pstack跟踪线程函数堆栈。

- gdb test 用gdb调试执行文件。
- attach pid 调试执行文件对应进程。
- thread apply all bt 所有线程查看函数的堆栈。
- 找到_lll_lock_wait 锁等待的地方。
- 然后查找该锁被哪个线程锁住了。
- p mutex_t 查看哪个线程拥有互斥锁。

```c++
1. 编译程序
   g++ -g a.cpp -o a.out
  
2. 编译完成后，运行之前要打开core dump开关
   ulimit -c unlimited
 
3. 运行程序
   [root@ia10k gdb]# ./a.out 
   only for a test
   only for a test
 
4. 查看进程id，使用kill命令产生core dump
   [root@ia10k gdb]# pidof a.out 
   21458
   [root@ia10k gdb]# kill -11 21458
   [root@ia10k gdb]# 
   # 这时可以看到进程已产生core dump
   [root@ia10k gdb]# ./a.out 
   only for a test
   only for a test
   Segmentation fault (core dumped)
   [root@ia10k gdb]# ls
   a.out  core.18734  deadlock.cpp
   [root@ia10k gdb]#  
 
5. gdb打开core文件
   [root@ia10k gdb]# gdb a.out core.18734
 
6. 打印所有线程的堆栈信息
(gdb) thread apply all bt
 
Thread 3 (Thread 0x7fdc50a40700 (LWP 18735)):
#0  0x00007fdc5799542d in __lll_lock_wait () from /usr/lib64/libpthread.so.0
#1  0x00007fdc57990dcb in _L_lock_812 () from /usr/lib64/libpthread.so.0
#2  0x00007fdc57990c98 in pthread_mutex_lock () from /usr/lib64/libpthread.so.0
#3  0x00000000004010dc in __gthread_mutex_lock (__mutex=0xeab098) at /usr/include/c++/4.8.2/x86_64-redhat-linux/bits/gthr-default.h:748
#4  0x000000000040141e in std::mutex::lock (this=0xeab098) at /usr/include/c++/4.8.2/mutex:134
#5  0x0000000000402575 in std::unique_lock<std::mutex>::lock (this=0x7fdc50a3fd80) at /usr/include/c++/4.8.2/mutex:511
#6  0x0000000000401f99 in std::unique_lock<std::mutex>::unique_lock (this=0x7fdc50a3fd80, __m=...) at /usr/include/c++/4.8.2/mutex:443
#7  0x000000000040183f in DataPool::pushToPool (this=0xeab058, inputData=std::shared_ptr (count 2, weak 0) 0x7fdc480008c0) at deadlock.cpp:53
#8  0x0000000000401c45 in FetchData::pushData (this=0xeab028) at deadlock.cpp:109
#9  0x0000000000405414 in std::_Mem_fn<void (FetchData::*)()>::_M_call<std::shared_ptr<FetchData>>(std::shared_ptr<FetchData>&&, void const volatile*) const (this=0xead6b0, 
    __ptr=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:558
#10 0x00000000004053a8 in std::_Mem_fn<void (FetchData::*)()>::operator()<std::shared_ptr<FetchData>, , void>(std::shared_ptr<FetchData>&&) const (this=0xead6b0, 
    __object=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:610
#11 0x0000000000405261 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::_M_invoke<0ul>(std::_Index_tuple<0ul>) (this=0xead6a0)
    at /usr/include/c++/4.8.2/functional:1732
#12 0x00000000004050b1 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::operator()() (this=0xead6a0) at /usr/include/c++/4.8.2/functional:1720
#13 0x0000000000404f90 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)> >::_M_run() (this=0xead688)
    at /usr/include/c++/4.8.2/thread:115
#14 0x00007fdc577342b0 in ?? () from /usr/lib64/libstdc++.so.6
#15 0x00007fdc5798ee25 in start_thread () from /usr/lib64/libpthread.so.0
#16 0x00007fdc56e9c34d in clone () from /usr/lib64/libc.so.6
 
Thread 2 (Thread 0x7fdc5023f700 (LWP 18736)):
#0  0x00007fdc5799542d in __lll_lock_wait () from /usr/lib64/libpthread.so.0
#1  0x00007fdc57990dcb in _L_lock_812 () from /usr/lib64/libpthread.so.0
#2  0x00007fdc57990c98 in pthread_mutex_lock () from /usr/lib64/libpthread.so.0
#3  0x00000000004010dc in __gthread_mutex_lock (__mutex=0xeab070) at /usr/include/c++/4.8.2/x86_64-redhat-linux/bits/gthr-default.h:748
#4  0x000000000040141e in std::mutex::lock (this=0xeab070) at /usr/include/c++/4.8.2/mutex:134
#5  0x0000000000402575 in std::unique_lock<std::mutex>::lock (this=0x7fdc5023ed90) at /usr/include/c++/4.8.2/mutex:511
#6  0x0000000000401f99 in std::unique_lock<std::mutex>::unique_lock (this=0x7fdc5023ed90, __m=...) at /usr/include/c++/4.8.2/mutex:443
#7  0x00000000004019f1 in DataPool::popFromPool (this=0xeab058, outData=std::shared_ptr (count 2, weak 0) 0x7fdc400008c0) at deadlock.cpp:68
#8  0x0000000000401d07 in FetchData::popData (this=0xeab028) at deadlock.cpp:119
#9  0x0000000000405414 in std::_Mem_fn<void (FetchData::*)()>::_M_call<std::shared_ptr<FetchData>>(std::shared_ptr<FetchData>&&, void const volatile*) const (this=0xead960, 
    __ptr=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:558
#10 0x00000000004053a8 in std::_Mem_fn<void (FetchData::*)()>::operator()<std::shared_ptr<FetchData>, , void>(std::shared_ptr<FetchData>&&) const (this=0xead960, 
    __object=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:610
#11 0x0000000000405261 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::_M_invoke<0ul>(std::_Index_tuple<0ul>) (this=0xead950)
---Type <return> to continue, or q <return> to quit---
    at /usr/include/c++/4.8.2/functional:1732
#12 0x00000000004050b1 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::operator()() (this=0xead950) at /usr/include/c++/4.8.2/functional:1720
#13 0x0000000000404f90 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)> >::_M_run() (this=0xead938)
    at /usr/include/c++/4.8.2/thread:115
#14 0x00007fdc577342b0 in ?? () from /usr/lib64/libstdc++.so.6
#15 0x00007fdc5798ee25 in start_thread () from /usr/lib64/libpthread.so.0
#16 0x00007fdc56e9c34d in clone () from /usr/lib64/libc.so.6
 
Thread 1 (Thread 0x7fdc57d9e740 (LWP 18734)):
#0  0x00007fdc5798ff57 in pthread_join () from /usr/lib64/libpthread.so.0
#1  0x00007fdc57734077 in std::thread::join() () from /usr/lib64/libstdc++.so.6
#2  0x0000000000401292 in main () at deadlock.cpp:131
(gdb) 
(gdb) 
 
7. 发现线程号为2和3的线程栈卡在lock_wait或者类似调用上，说明这几个线程极有可能产生死锁
 
8. info threads可以查看运行的线程，行首的数字表示gdb分配的线程号，切换线程时使用该号码，*表示的 是当前线程
(gdb) info threads
  Id   Target Id         Frame 
  3    Thread 0x7fdc50a40700 (LWP 18735) 0x00007fdc5799542d in __lll_lock_wait () from         /usr/lib64/libpthread.so.0
  2    Thread 0x7fdc5023f700 (LWP 18736) 0x00007fdc5799542d in __lll_lock_wait () from /usr/lib64/libpthread.so.0
* 1    Thread 0x7fdc57d9e740 (LWP 18734) 0x00007fdc5798ff57 in pthread_join () from /usr/lib64/libpthread.so.0
(gdb) 
 
9. 利用thread ID命令切换到怀疑的线程，打印锁的信息，Owner字段表示哪个线程持有这把锁，它是线程的lwp号，可以通过info threads查看，这里我们查看线程3，并打印堆栈信息
(gdb) thread 3
[Switching to thread 3 (Thread 0x7fdc50a40700 (LWP 18735))]
#0  0x00007fdc5799542d in __lll_lock_wait () from /usr/lib64/libpthread.so.0
(gdb) bt
#0  0x00007fdc5799542d in __lll_lock_wait () from /usr/lib64/libpthread.so.0
#1  0x00007fdc57990dcb in _L_lock_812 () from /usr/lib64/libpthread.so.0
#2  0x00007fdc57990c98 in pthread_mutex_lock () from /usr/lib64/libpthread.so.0
#3  0x00000000004010dc in __gthread_mutex_lock (__mutex=0xeab098) at /usr/include/c++/4.8.2/x86_64-redhat-linux/bits/gthr-default.h:748
#4  0x000000000040141e in std::mutex::lock (this=0xeab098) at /usr/include/c++/4.8.2/mutex:134
#5  0x0000000000402575 in std::unique_lock<std::mutex>::lock (this=0x7fdc50a3fd80) at /usr/include/c++/4.8.2/mutex:511
#6  0x0000000000401f99 in std::unique_lock<std::mutex>::unique_lock (this=0x7fdc50a3fd80, __m=...) at /usr/include/c++/4.8.2/mutex:443
#7  0x000000000040183f in DataPool::pushToPool (this=0xeab058, inputData=std::shared_ptr (count 2, weak 0) 0x7fdc480008c0) at deadlock.cpp:53
#8  0x0000000000401c45 in FetchData::pushData (this=0xeab028) at deadlock.cpp:109
#9  0x0000000000405414 in std::_Mem_fn<void (FetchData::*)()>::_M_call<std::shared_ptr<FetchData>>(std::shared_ptr<FetchData>&&, void const volatile*) const (this=0xead6b0, 
    __ptr=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:558
#10 0x00000000004053a8 in std::_Mem_fn<void (FetchData::*)()>::operator()<std::shared_ptr<FetchData>, , void>(std::shared_ptr<FetchData>&&) const (this=0xead6b0, 
    __object=<unknown type in /home/hls/demo/gdb/a.out, CU 0x0, DIE 0xbe6d>) at /usr/include/c++/4.8.2/functional:610
#11 0x0000000000405261 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::_M_invoke<0ul>(std::_Index_tuple<0ul>) (this=0xead6a0)
    at /usr/include/c++/4.8.2/functional:1732
#12 0x00000000004050b1 in std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)>::operator()() (this=0xead6a0) at /usr/include/c++/4.8.2/functional:1720
#13 0x0000000000404f90 in std::thread::_Impl<std::_Bind_simple<std::_Mem_fn<void (FetchData::*)()> (std::shared_ptr<FetchData>)> >::_M_run() (this=0xead688)
    at /usr/include/c++/4.8.2/thread:115
#14 0x00007fdc577342b0 in ?? () from /usr/lib64/libstdc++.so.6
#15 0x00007fdc5798ee25 in start_thread () from /usr/lib64/libpthread.so.0
#16 0x00007fdc56e9c34d in clone () from /usr/lib64/libc.so.6
(gdb) 
 
10. 可以看到堆栈最终卡在源码中的第53行，堆栈的第7层，我们使用frame命令查看第7层具体信息
(gdb) frame 7
#7  0x000000000040183f in DataPool::pushToPool (this=0xeab058, inputData=std::shared_ptr (count 2, weak 0) 0x7fdc480008c0) at deadlock.cpp:53
53			std::unique_lock<std::mutex> lckTwo(mutexTwo_);
(gdb) 
 
11. 查看一下lckTwo这把锁和mutexTwo_的信息
(gdb) p lckTwo 
$1 = {_M_device = 0xeab098, _M_owns = false}
(gdb) p mutexTwo_ 
$2 = {<std::__mutex_base> = {_M_mutex = {__data = {__lock = 2, __count = 0, __owner = 18736, __nusers = 1, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, 
      __size = "\002\000\000\000\000\000\000\000\060I\000\000\001", '\000' <repeats 26 times>, __align = 2}}, <No data fields>}
(gdb) 
# 这里我们可以看到线程3当前没有拥有lckTwo这把锁，互斥量mutexTwo_当前被lwp号为18736的线程占有，即线程2，那么这个时候我们就找到了死锁的具体点，通过审查线程2执行的代码，死锁很快就能定位出来，真实开发中出现的死锁问题，也可以通过gdb调试结合core dump分析来解决。
```

### 实现一个mutex互斥锁

实现mutex最重要的就是实现它的lock()方法和unlock()方法，我们保存一个全局变量flag，flag=1表明该锁已经锁住，flag=0表明锁没有锁住，实现lock()时，使用一个while循环不断检测flag是否等于1，如果等于1就一直循环，然后将flag设置为1；unlock()方法就将flag置为0。

```C++
static int flag=0;

void lock(){
  while(TestAndSet(&flag,1)==1);
  //flag=1;
}
void unlock(){
  flag=0;
}
```

因为while有可能被重入，所以可以用TestandSet()方法。

```C++
int TestAndSet(int *ptr, int new) {
    int old = *ptr;
    *ptr = new;
    return old;
}
```

### 原子操作和锁机制（1）

原子操作就是”不可中断的一个或一系列操作”。

#### 原子操作的实现

**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。**首先处理器会自动保证基本的内存操作的原子性，处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。

- 使用总线锁保证原子性：如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。**所谓总线锁就是使用处理器提供的一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。**
- 使用缓存锁保证原子性：在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但**总线锁定把CPU和内存之间的通信锁住了**，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在LOCK操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。**
  - 但是有两种情况下处理器不会使用缓存锁定：
    - 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。
    - 有些处理器不支持缓存锁定，对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。